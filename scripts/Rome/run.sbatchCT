#!/bin/bash
#options for sbatch
#SBATCH --account=PR_carisma
#SBATCH --job-name=CT/PTHA # Job name
#SBATCH --time=0-24:00 # time limit (D-HH:MM)
#SBATCH --nodes=1 # number of nodes
#SBATCH --partition=cpuq
#SBATCH --nodelist=cn07
# #SBATCH -p gpuq # partition
# #SBATCH --nodelist=gp01
# #SBATCH --gres=gpu:1 # number of GPUs
#SBATCH --output ./sbatch_logs/run-%j.txt       # Standard out goes to this file
#SBATCH --error ./sbatch_logs/error-%j.txt      # Standard err goes to this file
# #SBATCH --array=0-1%2 # number of jobs to run

# for calculating the amount of time the job takes
begin=`date +%s`
echo node: $HOSTNAME
echo start time: `date`
echo ...........

# setting up variables if provided
region=$1
size=$2
mode=$3
masksize=$4
split=$5
#TODO: add channels, zdim, and other hyper parameters  like batch size, learning rate, epoch of pretrian etc

# echo 'Running on' $region 'with' $size 'events' $mode 'mode' $masksize 'masksize'

# loading modules or conda
source /home/${USER}/.bash_profile # loading bash_proi
conda activate /mnt/beegfs/nragu/tsunami/env # conda environment

# running commands
cd $MLDir/scripts/Rome

#quick commands
# python checkgpu.py
# nvidia-smi

# echo 'Running 01_preprocess.py' 
# python 01_preprocess.py CT 1650 train 1650 #min first set
# python 01_preprocess.py CT 6091 train 1650 #second set
# python 01_preprocess.py CT 0 test 1650 #first test set
# python 01_preprocess.py CT 1 test 1650 #second test set
# python 01_preprocess.py CT 2 test 1650 #third test set
# python 01_preprocess.py CT 3 test 1650 #fourth test set

# echo 'Running jobs for encoders, decoders and coupled models' 
# python main.py with 'reg=CT' 'train_size=1650' 'mask_size=1650' 
# python test.py with 'reg=CT' 'train_size=1650' 'mask_size=1650' 'test_size=0' #evaluate
# python test.py with 'reg=CT' 'train_size=1650' 'mask_size=1650' 'test_size=1' #evaluate
# python test.py with 'reg=CT' 'train_size=1650' 'mask_size=1650' 'test_size=2' #evaluate
# python test.py with 'reg=CT' 'train_size=1650' 'mask_size=1650' 'test_size=3' #evaluate

# python main.py with 'reg=CT' 'train_size=6091' 'mask_size=1650' 
# python test.py with 'reg=CT' 'train_size=6091' 'mask_size=1650' 'test_size=0' #evaluate
# python test.py with 'reg=CT' 'train_size=6091' 'mask_size=1650' 'test_size=1' #evaluate
# python test.py with 'reg=CT' 'train_size=6091' 'mask_size=1650' 'test_size=2' #evaluate
# python test.py with 'reg=CT' 'train_size=6091' 'mask_size=1650' 'test_size=3' #evaluate

#post process
# setting up variables
# region=CT
# size=0
# mode=post
# masksize=1650

# # Adjusting test/train size based on array task id
# if [[ ${SLURM_ARRAY_TASK_ID} -lt 4 ]]; then
#     train_size=1650
# else
#     train_size=6091
# fi

# test_size=$(( ${SLURM_ARRAY_TASK_ID} % 4 ))

# echo "Running 02_postprocess.py for test size: $test_size and train size: $train_size" 
# python 02_postprocess.py $region $test_size $mode $train_size $masksize

#evaluation of post processed results
# echo "Running final evaluation with postprocessed prediction for test size: $test_size and train size: $train_size" 
# python test.py with "reg=$region" "train_size=$train_size" "mask_size=$masksize" "test_size=$test_size"

#reprocess the results to a single binary file
# echo "Reprocessing the results to a single binary file for train size: $train_size"
# python 03_reprocess.py CT reprocess 1650
# python 03_reprocess.py CT reprocess 6091

#PTHA calculation
echo "PTHA processing for all grids"
python 04_calcPTHA.py CT PTHA 1650 1650
# python 04_calcPTHA.py CT reprocess 6091 1650

# finished commands
echo ...........
end=`date +%s`
elapsed=`expr $end - $begin`
echo Time taken: $elapsed seconds