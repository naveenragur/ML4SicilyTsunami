{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Offshore Gauge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/mnt/beegfs/nragu/tsunami/ML4SicilyTsunami/data/simu/old/PS_manning003/E01517N3917E01678N3772-PS-Mur_PNo_Hom-M792_E01620N3835_S000/grid0_ts.nc'\n",
    "import xarray as xr\n",
    "import scipy.signal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#read data\n",
    "data = xr.open_dataset(file)\n",
    "depth = data['deformed_bathy'].values\n",
    "ts = data['eta'].values\n",
    "maxTS = ts.max(axis=0)\n",
    "minTS = ts.min(axis=0)\n",
    "gperiod = []\n",
    "gpolarity = []\n",
    "greturn_code = []\n",
    "\n",
    "for g in range(87):\n",
    "    #find peaks(positive and negative)\n",
    "    ppeaks, _ = scipy.signal.find_peaks(ts[:,g], height=0.05,distance=50)\n",
    "    npeaks, _ = scipy.signal.find_peaks(-ts[:,g], height=0.05,distance=50)\n",
    "\n",
    "    #find polarity of wave based on positive and negative peaks indices\n",
    "    if len(ppeaks)==0 and len(npeaks)==0:\n",
    "        polarity = '0'\n",
    "    elif len(ppeaks)==0:\n",
    "        polarity = '-1'\n",
    "    elif len(npeaks)==0:\n",
    "        polarity = '+1'\n",
    "    elif ppeaks[0]<npeaks[0]:\n",
    "        polarity = '+1'\n",
    "    elif ppeaks[0]>npeaks[0]:\n",
    "        polarity = '-1'\n",
    "    else:\n",
    "        polarity = '0'\n",
    "\n",
    "    #find waveperiod\n",
    "    if polarity == '0':\n",
    "        waveperiod = 0\n",
    "    elif polarity == '+1':\n",
    "        waveperiod = (ppeaks[1]-ppeaks[0])*30\n",
    "    elif polarity == '-1':\n",
    "        waveperiod = (npeaks[1]-npeaks[0])*30\n",
    "\n",
    "    #return code\n",
    "    if polarity == '0':\n",
    "        return_code = 1\n",
    "    elif polarity == '+1' or polarity == '-1':\n",
    "        return_code = 3\n",
    "\n",
    "    gperiod.append(waveperiod)\n",
    "    gpolarity.append(polarity)\n",
    "    greturn_code.append(return_code)\n",
    "\n",
    "gperiod = np.array(gperiod)\n",
    "gpolarity = np.array(gpolarity)\n",
    "greturn_code = np.array(greturn_code)\n",
    "\n",
    "\n",
    "#compile to dataframe #ID lon lat depth max_ssh min_ssh period polarity return_code\n",
    "df = pd.DataFrame({'ID':np.arange(87)+1,\n",
    "                    'lon':data['longitude'].values,\n",
    "                    'lat':data['latitude'].values,\n",
    "                    'depth':data['deformed_bathy'].values,\n",
    "                    'max_ssh':maxTS,\n",
    "                    'min_ssh':minTS,\n",
    "                    'period':gperiod,\n",
    "                    'polarity':gpolarity,\n",
    "                    'return_code':greturn_code})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Event Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_list = ['/mnt/beegfs/nragu/tsunami/ML4SicilyTsunami/resources/processed/eve_rate/med09159_BS_mih1.0-4.0_probs99ALL.txt',\n",
    "            '/mnt/beegfs/nragu/tsunami/ML4SicilyTsunami/resources/processed/eve_rate/med09159_PS_mih1.0-4.0_probs99ALL.txt',\n",
    "            '/mnt/beegfs/nragu/tsunami/ML4SicilyTsunami/resources/processed/eve_rate/med09174_BS_probs99ALL.txt',\n",
    "            '/mnt/beegfs/nragu/tsunami/ML4SicilyTsunami/resources/processed/eve_rate/med09174_PS_probs99ALL.txt']\n",
    "all_events = pd.DataFrame()\n",
    "\n",
    "for f,file in enumerate(file_list):\n",
    "    print(file)\n",
    "    #read file and calculate mean probability for each event stored as a row( event_id, prob0....prob999)\n",
    "    df = pd.read_csv(file, sep=',')\n",
    "    # append first column and mean to a new dataframe\n",
    "    df_mean = pd.DataFrame({'ID':df.iloc[:,0],\n",
    "                        'mean_prob':df.iloc[:,1:].mean(axis=1)})\n",
    "    #append to all_events\n",
    "    all_events = pd.concat([all_events,df_mean],axis=0)\n",
    "    del df, df_mean\n",
    "    \n",
    "#drop duplicates\n",
    "all_events.drop_duplicates(subset='ID', keep='first', inplace=True)\n",
    "\n",
    "#save to file\n",
    "all_events.to_csv('/mnt/beegfs/nragu/tsunami/ML4SicilyTsunami/resources/processed/all_eventsBS_PS53550_meanrate.txt', sep=',', index=False)\n",
    "\n",
    "#read event info file\n",
    "event_info = pd.read_csv('/mnt/beegfs/nragu/tsunami/ML4SicilyTsunami/resources/processed/all_eventsBS_PS53550.txt',sep='\\t')\n",
    "\n",
    "#merge event info and mean rate\n",
    "combined = pd.merge(event_info, all_events, on='ID', how='left')\n",
    "\n",
    "#save to file\n",
    "combined.to_csv('/mnt/beegfs/nragu/tsunami/ML4SicilyTsunami/resources/processed/allinfo_eventsBS_PS53550.txt', sep=',', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check duplicates in id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check duplicates in id\n",
    "len(all_events[all_events.duplicated(subset=['id'])])\n",
    "\n",
    "#find one duplicate\n",
    "all_events[all_events.duplicated(subset=['id'])].iloc[888,0]\n",
    "\n",
    "#print one entry where id is 'E01267N3753E01646N3535-BS-M707_E01527N3715_D010_S067D50R090_A000668_S023'\n",
    "all_events[all_events['id']==all_events[all_events.duplicated(subset=['id'])].iloc[2000,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder_coupled(\n",
       "  (offshore_encoder): Sequential(\n",
       "    (0): Conv1d(5, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): LeakyReLU(negative_slope=0.5, inplace=True)\n",
       "    (2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (3): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (4): LeakyReLU(negative_slope=0.5, inplace=True)\n",
       "    (5): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (6): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (7): LeakyReLU(negative_slope=0.5, inplace=True)\n",
       "    (8): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (9): Dropout(p=0.1, inplace=False)\n",
       "    (10): Flatten(start_dim=1, end_dim=-1)\n",
       "    (11): Linear(in_features=15360, out_features=64, bias=True)\n",
       "  )\n",
       "  (deform_encoder): Sequential(\n",
       "    (0): Linear(in_features=186181, out_features=64, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "  )\n",
       "  (connect): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "  )\n",
       "  (onshore_decoder): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (2): Linear(in_features=64, out_features=186181, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "import model_utils as utils\n",
    "import torch\n",
    "model = torch.load(f\"/mnt/beegfs/nragu/tsunami/ML4SicilyTsunami/model/SR/out/model_coupled_off[64, 128, 256]_on[64, 64]_epoch_1000_900.pt\",map_location=torch.device('cpu'))\n",
    "model.eval()\n",
    "# summary(model,[(5,480),(186181,)])\n",
    "summary(model,[(5,480),(186181,)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1              [-1, 64, 480]           1,024\n",
      "         LeakyReLU-2              [-1, 64, 480]               0\n",
      "         AvgPool1d-3              [-1, 64, 240]               0\n",
      "            Conv1d-4             [-1, 128, 240]          24,704\n",
      "         LeakyReLU-5             [-1, 128, 240]               0\n",
      "         AvgPool1d-6             [-1, 128, 120]               0\n",
      "            Conv1d-7             [-1, 256, 120]          98,560\n",
      "         LeakyReLU-8             [-1, 256, 120]               0\n",
      "         AvgPool1d-9              [-1, 256, 60]               0\n",
      "          Dropout-10              [-1, 256, 60]               0\n",
      "          Flatten-11                [-1, 15360]               0\n",
      "           Linear-12                   [-1, 64]         983,104\n",
      "           Linear-13                   [-1, 64]      11,915,648\n",
      "        LeakyReLU-14                   [-1, 64]               0\n",
      "           Linear-15                   [-1, 64]           4,160\n",
      "        LeakyReLU-16                   [-1, 64]               0\n",
      "           Linear-17                   [-1, 64]           8,256\n",
      "        LeakyReLU-18                   [-1, 64]               0\n",
      "           Linear-19                   [-1, 64]           4,160\n",
      "        LeakyReLU-20                   [-1, 64]               0\n",
      "           Linear-21                   [-1, 64]           4,160\n",
      "        LeakyReLU-22                   [-1, 64]               0\n",
      "           Linear-23               [-1, 186181]      12,101,765\n",
      "        LeakyReLU-24               [-1, 186181]               0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# summary(model,[(5,480),(186181,)])\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m summary(model,[(\u001b[39m5\u001b[39;49m,\u001b[39m480\u001b[39;49m),(\u001b[39m186181\u001b[39;49m,)])\n",
      "File \u001b[0;32m/mnt/beegfs/nragu/tsunami/env/lib/python3.10/site-packages/torchsummary/torchsummary.py:100\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[39mprint\u001b[39m(line_new)\n\u001b[1;32m     99\u001b[0m \u001b[39m# assume 4 bytes/number (float on cuda).\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m total_input_size \u001b[39m=\u001b[39m \u001b[39mabs\u001b[39m(np\u001b[39m.\u001b[39;49mprod(input_size) \u001b[39m*\u001b[39m batch_size \u001b[39m*\u001b[39m \u001b[39m4.\u001b[39m \u001b[39m/\u001b[39m (\u001b[39m1024\u001b[39m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2.\u001b[39m))\n\u001b[1;32m    101\u001b[0m total_output_size \u001b[39m=\u001b[39m \u001b[39mabs\u001b[39m(\u001b[39m2.\u001b[39m \u001b[39m*\u001b[39m total_output \u001b[39m*\u001b[39m \u001b[39m4.\u001b[39m \u001b[39m/\u001b[39m (\u001b[39m1024\u001b[39m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2.\u001b[39m))  \u001b[39m# x2 for gradients\u001b[39;00m\n\u001b[1;32m    102\u001b[0m total_params_size \u001b[39m=\u001b[39m \u001b[39mabs\u001b[39m(total_params\u001b[39m.\u001b[39mnumpy() \u001b[39m*\u001b[39m \u001b[39m4.\u001b[39m \u001b[39m/\u001b[39m (\u001b[39m1024\u001b[39m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2.\u001b[39m))\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mprod\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/mnt/beegfs/nragu/tsunami/env/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3076\u001b[0m, in \u001b[0;36mprod\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2955\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_prod_dispatcher)\n\u001b[1;32m   2956\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprod\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue,\n\u001b[1;32m   2957\u001b[0m          initial\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue, where\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue):\n\u001b[1;32m   2958\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2959\u001b[0m \u001b[39m    Return the product of array elements over a given axis.\u001b[39;00m\n\u001b[1;32m   2960\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[39m    10\u001b[39;00m\n\u001b[1;32m   3075\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3076\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49mmultiply, \u001b[39m'\u001b[39;49m\u001b[39mprod\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, dtype, out,\n\u001b[1;32m   3077\u001b[0m                           keepdims\u001b[39m=\u001b[39;49mkeepdims, initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[0;32m/mnt/beegfs/nragu/tsunami/env/lib/python3.10/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39;49mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
