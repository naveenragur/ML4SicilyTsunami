#!/bin/bash
#options for sbatch
#SBATCH --account=PR_carisma
#SBATCH --job-name=CTpPTHA # Job name
#SBATCH --time=0-24:00 # time limit (D-HH:MM)
#SBATCH --nodes=1 # number of nodes
#SBATCH --partition=cpuq
#SBATCH --nodelist=cn06
# #SBATCH -p gpuq # partition
# #SBATCH --gres=gpu:1 # number of GPUs
# #SBATCH --nodelist=gp02
#SBATCH --output ./sbatch_logs/run-%j.txt       # Standard out goes to this file
#SBATCH --error ./sbatch_logs/error-%j.txt      # Standard err goes to this file
# #SBATCH --array=12-15%4 # number of jobs to run

# for calculating the amount of time the job takes
begin=`date +%s`
echo node: $HOSTNAME
echo start time: `date`
echo ...........

# setting up variables if provided
region=$1
size=$2
mode=$3
masksize=$4
split=$5
#TODO: add channels, zdim, and other hyper parameters  like batch size, learning rate, epoch of pretrian etc

# echo 'Running on' $region 'with' $size 'events' $mode 'mode' $masksize 'masksize'

# loading modules or conda
source /home/${USER}/.bash_profile # loading bash_proi
conda activate /mnt/beegfs/nragu/tsunami/env # conda environment
# conda activate rioxarray_env

# running commands
cd $MLDir/scripts/PaperIIRuns

#quick commands
# export CUDA_VISIBLE_DEVICES=1
# python checkgpu.py
# nvidia-smi

#processing the data to memmap files
# echo 'Running 01_preprocess.py' 
# python 01_preprocess.py CT 892 train 892 #min first set
# python 01_preprocess.py CT 1658 train 892 #second set
# python 01_preprocess.py CT 3454 train 892 #third set
# python 01_preprocess.py CT 7071 train 892 #fourth set
# python 01_preprocess.py CT 7929 train 892 #deformation pretraining
# python 01_preprocess.py CT 0 test 892 #first test set
# python 01_preprocess.py CT 1 test 892 #second test set
# python 01_preprocess.py CT 2 test 892 #third test set
# python 01_preprocess.py CT 3 test 892 #fourth test set

#pretraining encoders and decoders
# python main.py with 'reg=CT' 'train_size=7071' 'mask_size=892' #offshore with 7071 mix events 
# python main.py with 'reg=CT' 'train_size=7929' 'mask_size=892' #deform with 7929 deform events
# python main.py with 'reg=CT' 'train_size=892' 'mask_size=892' #onshore with diff sizes
# python main.py with 'reg=CT' 'train_size=1658' 'mask_size=892' 
# python main.py with 'reg=CT' 'train_size=3454' 'mask_size=892' 
# python main.py with 'reg=CT' 'train_size=7071' 'mask_size=892' 

#direct training - fulltuneED with or without deform input and then test
# echo 'Running jobs for direct models' 

# python main.py with 'reg=CT' 'train_size=892' 'mask_size=892'
# python main.py with 'reg=CT' 'train_size=1658' 'mask_size=892'
# python main.py with 'reg=CT' 'train_size=3454' 'mask_size=892'
# python main.py with 'reg=CT' 'train_size=7071' 'mask_size=892'

# python main_test.py with 'reg=CT' 'train_size=892' 'mask_size=892' 'test_size=0' #evaluate
# python main_test.py with 'reg=CT' 'train_size=892' 'mask_size=892' 'test_size=1' #evaluate
# python main_test.py with 'reg=CT' 'train_size=892' 'mask_size=892' 'test_size=2' #evaluate
# python main_test.py with 'reg=CT' 'train_size=892' 'mask_size=892' 'test_size=3' #evaluate

# python main_test.py with 'reg=CT' 'train_size=1658' 'mask_size=892' 'test_size=0' #evaluate
# python main_test.py with 'reg=CT' 'train_size=1658' 'mask_size=892' 'test_size=1' #evaluate
# python main_test.py with 'reg=CT' 'train_size=1658' 'mask_size=892' 'test_size=2' #evaluate
# python main_test.py with 'reg=CT' 'train_size=1658' 'mask_size=892' 'test_size=3' #evaluate

# python main_test.py with 'reg=CT' 'train_size=3454' 'mask_size=892' 'test_size=0' #evaluate
# python main_test.py with 'reg=CT' 'train_size=3454' 'mask_size=892' 'test_size=1' #evaluate
# python main_test.py with 'reg=CT' 'train_size=3454' 'mask_size=892' 'test_size=2' #evaluate
# python main_test.py with 'reg=CT' 'train_size=3454' 'mask_size=892' 'test_size=3' #evaluate

# python main_test.py with 'reg=CT' 'train_size=7071' 'mask_size=892' 'test_size=0' #evaluate
# python main_test.py with 'reg=CT' 'train_size=7071' 'mask_size=892' 'test_size=1' #evaluate
# python main_test.py with 'reg=CT' 'train_size=7071' 'mask_size=892' 'test_size=2' #evaluate
# python main_test.py with 'reg=CT' 'train_size=7071' 'mask_size=892' 'test_size=3' #evaluate

# echo 'Running jobs for encoders, decoders and coupled models' 
# python train.py with 'reg=CT' 'train_size=892' 'mask_size=892' 'off_size=7071' 'deform_size=7929'
# python test.py with 'reg=CT' 'train_size=892' 'mask_size=892' 'test_size=0' #evaluate
# python test.py with 'reg=CT' 'train_size=892' 'mask_size=892' 'test_size=1' #evaluate
# python test.py with 'reg=CT' 'train_size=892' 'mask_size=892' 'test_size=2' #evaluate
# python test.py with 'reg=CT' 'train_size=892' 'mask_size=892' 'test_size=3' #evaluate

# python train.py with 'reg=CT' 'train_size=1658' 'mask_size=892' 'off_size=7071' 'deform_size=7929'
# python test.py with 'reg=CT' 'train_size=1658' 'mask_size=892' 'test_size=0' #evaluate
# python test.py with 'reg=CT' 'train_size=1658' 'mask_size=892' 'test_size=1' #evaluate
# python test.py with 'reg=CT' 'train_size=1658' 'mask_size=892' 'test_size=2' #evaluate
# python test.py with 'reg=CT' 'train_size=1658' 'mask_size=892' 'test_size=3' #evaluate

# python train.py with 'reg=CT' 'train_size=3454' 'mask_size=892' 'off_size=7071' 'deform_size=7929'
# python test.py with 'reg=CT' 'train_size=3454' 'mask_size=892' 'test_size=0' #evaluate
# python test.py with 'reg=CT' 'train_size=3454' 'mask_size=892' 'test_size=1' #evaluate
# python test.py with 'reg=CT' 'train_size=3454' 'mask_size=892' 'test_size=2' #evaluate
# python test.py with 'reg=CT' 'train_size=3454' 'mask_size=892' 'test_size=3' #evaluate

# python train.py with 'reg=CT' 'train_size=7071' 'mask_size=892' 'off_size=7071' 'deform_size=7929' 
# python test.py with 'reg=CT' 'train_size=7071' 'mask_size=892' 'test_size=0' #evaluate
# python test.py with 'reg=CT' 'train_size=7071' 'mask_size=892' 'test_size=1' #evaluate
# python test.py with 'reg=CT' 'train_size=7071' 'mask_size=892' 'test_size=2' #evaluate
# python test.py with 'reg=CT' 'train_size=7071' 'mask_size=892' 'test_size=3' #evaluate

###########NOT USED#################
# #post process
# # Define arrays for train sizes and test sizes
# region=CT
# mode=post
# masksize=892
# train_sizes=(892 1658 3454 7071)
# test_sizes=(0 1 2 3)
# # Calculate index for train_size and test_size based on SLURM_ARRAY_TASK_ID
# train_index=$((SLURM_ARRAY_TASK_ID / 4))
# test_index=$((SLURM_ARRAY_TASK_ID % 4))
# train_size=${train_sizes[$train_index]}
# test_size=${test_sizes[$test_index]}
# # echo "Running 02_postprocess.py for test size: $test_size and train size: $train_size" 
# # python 02_postprocess.py $region $test_size $mode $train_size $masksize

# #evaluation of post processed results
# echo "Running final evaluation with postprocessed prediction for test size: $test_size and train size: $train_size" 
# python test.py with "reg=$region" "train_size=$train_size" "mask_size=$masksize" "test_size=$test_size"

#reprocess the results to a single binary file
# echo "Reprocessing the results to a single binary file for train size: $train_size"
# python 03_reprocess.py CT reprocess 892
# python 03_reprocess.py CT reprocess 1658
# python 03_reprocess.py CT reprocess 3454
# python 03_reprocess.py CT reprocess 7071


#compile results to a single npy file of int 16 with cm values
# echo "processing for all grids, all events into a single file"
# python 04_compile_depths.py CT compile 1658 892

#Grid calculation
# echo "Performance calculation for all grids"
# python 05_calcPerfGrid.py CT Grid 1658 892
#For comparison with paper1
# python 05_calcPerfGrid.py CT testfile 1658 892
#For misfit plot all events all grids distribution
# python 05_calcPerfGrid.py CT misfit 1658 892

#For comparison plots
# python 06_compare_depths.py CT compare_pygmt 1658 892

#For plotting PTHA maps for true depths
# python 07_calcPTHA.py CT PTHA_rate 1658 892
python 07_calcPTHA.py CT emulator_rate 1658 892 

# finished commands
echo ...........
end=`date +%s`
elapsed=`expr $end - $begin`
echo Time taken: $elapsed seconds